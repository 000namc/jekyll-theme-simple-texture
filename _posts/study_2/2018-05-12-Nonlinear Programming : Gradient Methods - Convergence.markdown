---
layout: post
title: "Nonlinear Programming : Gradient Methods - Convergence(작성중)"
categories: study_2
comments: true
tags: [study, optimization]
redirect_from:
  - /2018/05/12/
---

- [2018-05-01 : 스터디 소개 : Nonlinear Programming Study](https://000namc.github.io/blog/2018/05/01/Nonlinear-Programming/)
- [2018-05-02 : 스터디 소개 : Nonlinear Programming : Optimality Condition Study](https://000namc.github.io/blog/2018/05/02/Nonlinear-Programming-Optimality-Condition/)
- [2018-05-12 : 스터디 소개 : Nonlinear Programming : Gradient Methods - Convergence(작성중) Study](https://000namc.github.io/blog/2018/05/12/Nonlinear-Programming-Gradient-Methods-Convergence/) $\leftarrow$  


1장의 목차는 아래와 같습니다. 이중에 1.2 Gradient Methods - Convergence 에 대해 정리하려고 합니다.

**1. Unconstrained Optimization**  
1.1 Optimality Condition  
**1.2 Gradient Methods - Convergence**  
1.3 Gradient Methods - Rate of Convergence  
1.4 Newton's Method and Variations  
1.5 Least Squares Problems  
1.6 Conjugate Direction Methods  
1.7 Quasi-Newton Methods  
1.8 Nonderivative Methods  
1.9 Discrete-Time Optimal Control  
1.10 Some Practical Guidelines  
1.11 Notes and Sources  


## 1 Unconstrained Optimization    
### 1.2 Gradient Methods - Convergence  
